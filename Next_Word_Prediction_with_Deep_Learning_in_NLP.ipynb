{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "REhRO6uS2sMy"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "import regex as re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "uAFnxDKg2v_2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Text data successfully processed!\n"
          ]
        }
      ],
      "source": [
        "def file_to_sentence_list(file_path):\n",
        "    \"\"\"Read a file and split its content into sentences.\"\"\"\n",
        "    try:\n",
        "        # Open the file with UTF-8 encoding\n",
        "        with open(file_path, 'r', encoding='utf-8') as file:\n",
        "            text = file.read()\n",
        "\n",
        "        # Splitting the text into sentences using delimiters like '.', '?', and '!'\n",
        "        sentences = [sentence.strip() for sentence in re.split(\n",
        "            r'(?<=[.!?])\\s+', text) if sentence.strip()]\n",
        "\n",
        "        return sentences\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: The file '{file_path}' does not exist.\")\n",
        "        return []\n",
        "    except UnicodeDecodeError as e:\n",
        "        print(f\"Encoding error: {e}\")\n",
        "        return []\n",
        "\n",
        "# File path\n",
        "file_path = 'pizza.txt'\n",
        "\n",
        "# Process text data\n",
        "text_data = file_to_sentence_list(file_path)\n",
        "\n",
        "if not text_data:\n",
        "    print(\"No valid text data to process.\")\n",
        "else:\n",
        "    # Tokenize the text data\n",
        "    tokenizer = Tokenizer()\n",
        "    tokenizer.fit_on_texts(text_data)\n",
        "    total_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "    # Create input sequences\n",
        "    input_sequences = []\n",
        "    for line in text_data:\n",
        "        token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "        for i in range(1, len(token_list)):\n",
        "            n_gram_sequence = token_list[:i + 1]\n",
        "            input_sequences.append(n_gram_sequence)\n",
        "\n",
        "    # Pad sequences and split into predictors and label\n",
        "    max_sequence_len = max([len(seq) for seq in input_sequences])\n",
        "    input_sequences = np.array(pad_sequences(\n",
        "        input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "    X, y = input_sequences[:, :-1], input_sequences[:, -1]\n",
        "\n",
        "    # Convert target data to one-hot encoding\n",
        "    y = tf.keras.utils.to_categorical(y, num_classes=total_words)\n",
        "\n",
        "    print(\"Text data successfully processed!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2O9gDY227_f",
        "outputId": "2c4aaaa7-7a28-40e4-f325-e34cef9bca18"
      },
      "outputs": [],
      "source": [
        "# Define the model  (USE THIS CELL ONLY ONCE TO CREATE AND SAVE MODEL, AFTER THAT COMMENT OUT THIS CELL)\n",
        "model = Sequential()\n",
        "model.add(Embedding(total_words, 10,\n",
        "\t\t\t\t\tinput_length=max_sequence_len-1))\n",
        "model.add(LSTM(128))\n",
        "model.add(Dense(total_words, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "\t\t\toptimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "# Train the model\n",
        "model.fit(X, y, epochs=100, verbose=1)\n",
        "\n",
        "# Save the model\n",
        "model.save(\"Next_Word_Prediction_with_Deep_Learning_in_NLP.keras\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "you\n",
            "Next predicted words: how are you\n"
          ]
        }
      ],
      "source": [
        "# Load the saved model\n",
        "model = load_model('Next_Word_Prediction_with_Deep_Learning_in_NLP.keras')\n",
        "\n",
        "# Parameters\n",
        "max_sequence_len = model.input_shape[1] + 1  # Calculate based on the model's input shape\n",
        "\n",
        "# Generate next word predictions\n",
        "seed_text = \"how are\"\n",
        "next_words = 1\n",
        "\n",
        "for _ in range(next_words):\n",
        "    # Convert seed text to sequences using the existing tokenizer\n",
        "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "    # Pad the sequence to match the model's expected input length\n",
        "    token_list = pad_sequences([token_list], maxlen=max_sequence_len - 1, padding='pre')\n",
        "    # Predict the next word probabilities\n",
        "    predicted_probs = model.predict(token_list, verbose=0)\n",
        "    # Get the word with the highest probability\n",
        "    predicted_word = tokenizer.index_word.get(np.argmax(predicted_probs), '')\n",
        "    # Append the predicted word to the seed text\n",
        "    seed_text += \" \" + predicted_word\n",
        "\n",
        "print(predicted_word)\n",
        "print(\"Next predicted words:\", seed_text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Text editor with word prediction integrated "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tkinter as tk\n",
        "from tkinter import font\n",
        "from tkinter import filedialog, messagebox\n",
        "from docx import Document\n",
        "from docx.shared import Pt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the saved model and tokenizer\n",
        "model = load_model('Next_Word_Prediction_with_Deep_Learning_in_NLP.keras')\n",
        "\n",
        "# Parameters\n",
        "max_sequence_len = model.input_shape[1] + 1  # Calculate based on the model's input shape\n",
        "\n",
        "# Placeholder for the suggestion word\n",
        "suggested_word = \"example\"\n",
        "\n",
        "def toggle_formatting(tag, font_style=None):\n",
        "    \"\"\"Toggle formatting like bold, italic, or underline on selected text.\"\"\"\n",
        "    try:\n",
        "        start_index = text.index(\"sel.first\")\n",
        "        end_index = text.index(\"sel.last\")\n",
        "\n",
        "        if tag in text.tag_names(\"sel.first\"):\n",
        "            text.tag_remove(tag, \"sel.first\", \"sel.last\")\n",
        "        else:\n",
        "            text.tag_add(tag, \"sel.first\", \"sel.last\")\n",
        "            text.tag_configure(tag, font=(current_font.get(), 12, font_style))\n",
        "    except tk.TclError:\n",
        "        messagebox.showwarning(\"Warning\", \"No text selected to apply formatting!\")\n",
        "\n",
        "def change_font(event=None):\n",
        "    \"\"\"Change font style for the selected text.\"\"\"\n",
        "    selected_font = current_font.get()\n",
        "    text.config(font=(selected_font, 12))\n",
        "\n",
        "def toggle_case(case_type):\n",
        "    \"\"\"Toggle between uppercase and lowercase for selected text.\"\"\"\n",
        "    try:\n",
        "        start_index = text.index(\"sel.first\")\n",
        "        end_index = text.index(\"sel.last\")\n",
        "        selected_text = text.get(\"sel.first\", \"sel.last\")\n",
        "        new_text = (\n",
        "            selected_text.upper() if case_type == \"uppercase\" else selected_text.lower()\n",
        "        )\n",
        "        text.delete(\"sel.first\", \"sel.last\")\n",
        "        text.insert(start_index, new_text)\n",
        "    except tk.TclError:\n",
        "        messagebox.showwarning(\"Warning\", \"No text selected to toggle case!\")\n",
        "\n",
        "def save_as_docx():\n",
        "    \"\"\"Save the content to a DOCX file with proper formatting.\"\"\"\n",
        "    file_name = file_name_entry.get()\n",
        "    if not file_name:\n",
        "        messagebox.showwarning(\"Warning\", \"Please enter a file name before saving!\")\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        file_path = filedialog.asksaveasfilename(\n",
        "            defaultextension=\".docx\", initialfile=file_name, filetypes=[(\"Word Files\", \"*.docx\")]\n",
        "        )\n",
        "        if file_path:\n",
        "            doc = Document()\n",
        "\n",
        "            # Get the selected font from the current font variable\n",
        "            selected_font = current_font.get()\n",
        "\n",
        "            # Add the text content to the DOCX file with formatting\n",
        "            for line_index, line in enumerate(text.get(\"1.0\", \"end\").splitlines()):\n",
        "                paragraph = doc.add_paragraph()\n",
        "\n",
        "                tags = text.tag_names(f\"{line_index + 1}.0\")\n",
        "                run = paragraph.add_run(line)\n",
        "\n",
        "                # Apply font styling based on selected tags\n",
        "                if \"bold\" in tags:\n",
        "                    run.bold = True\n",
        "                if \"italic\" in tags:\n",
        "                    run.italic = True\n",
        "                if \"underline\" in tags:\n",
        "                    run.underline = True\n",
        "\n",
        "                run.font.name = selected_font\n",
        "                run.font.size = Pt(12)  # Set the font size to 12pt\n",
        "\n",
        "            doc.save(file_path)\n",
        "            messagebox.showinfo(\"Success\", \"File saved successfully as DOCX!\")\n",
        "    except Exception as e:\n",
        "        messagebox.showerror(\"Error\", f\"Could not save file: {e}\")\n",
        "\n",
        "def toggle_theme():\n",
        "    \"\"\"Toggle between light and dark mode.\"\"\"\n",
        "    if theme_button.config('text')[-1] == 'Dark Mode':\n",
        "        text.config(bg=\"white\", fg=\"black\", insertbackground=\"black\")\n",
        "        root.config(bg=\"white\")\n",
        "        toolbar.config(bg=\"white\")\n",
        "        for widget in toolbar.winfo_children():\n",
        "            widget.config(bg=\"white\", fg=\"black\")\n",
        "        theme_button.config(text=\"Light Mode\")\n",
        "    else:\n",
        "        text.config(bg=\"black\", fg=\"white\", insertbackground=\"white\")\n",
        "        root.config(bg=\"black\")\n",
        "        toolbar.config(bg=\"black\")\n",
        "        for widget in toolbar.winfo_children():\n",
        "            widget.config(bg=\"black\", fg=\"white\")\n",
        "        theme_button.config(text=\"Dark Mode\")\n",
        "\n",
        "def get_suggestion(last_words):\n",
        "    \"\"\"Predict the next word based on the last few words.\"\"\"\n",
        "    global suggested_word\n",
        "    # Convert the last words to sequences\n",
        "    token_list = tokenizer.texts_to_sequences([\" \".join(last_words)])[0]\n",
        "    token_list = pad_sequences([token_list], maxlen=max_sequence_len - 1, padding='pre')\n",
        "    \n",
        "    # Predict the next word\n",
        "    predicted_probs = model.predict(token_list, verbose=0)\n",
        "    suggested_word = tokenizer.index_word.get(np.argmax(predicted_probs), '')\n",
        "    \n",
        "    # Update the suggestion label with the predicted word\n",
        "    suggestion_label.config(text=f\"Suggested word (Press Tab): {suggested_word}\")\n",
        "\n",
        "def update_last_words(event=None):\n",
        "    \"\"\"Fetch the last five words and generate a word suggestion.\"\"\"\n",
        "    current_text = text.get(\"1.0\", \"end\").strip()\n",
        "    words = current_text.split()\n",
        "    last_five_words = words[-5:] if len(words) > 5 else words\n",
        "    if last_five_words:\n",
        "        get_suggestion(last_five_words)\n",
        "\n",
        "def insert_suggestion(event=None):\n",
        "    \"\"\"Insert the suggested word at the current cursor position.\"\"\"\n",
        "    text.insert(tk.INSERT, f\"{suggested_word} \")\n",
        "\n",
        "# Create the main application window\n",
        "root = tk.Tk()\n",
        "root.title(\"Enhanced Text Editor\")\n",
        "root.geometry(\"1000x600\")\n",
        "\n",
        "current_font = tk.StringVar(value=\"Arial\")\n",
        "\n",
        "toolbar = tk.Frame(root)\n",
        "toolbar.pack(fill=\"x\", padx=5, pady=5)\n",
        "\n",
        "font_label = tk.Label(toolbar, text=\"Font:\")\n",
        "font_label.pack(side=\"left\", padx=5)\n",
        "\n",
        "font_menu = tk.OptionMenu(toolbar, current_font, *font.families(), command=change_font)\n",
        "font_menu.pack(side=\"left\", padx=5)\n",
        "\n",
        "bold_btn = tk.Button(toolbar, text=\"Bold\", command=lambda: toggle_formatting(\"bold\", \"bold\"))\n",
        "bold_btn.pack(side=\"left\", padx=5)\n",
        "\n",
        "italic_btn = tk.Button(toolbar, text=\"Italic\", command=lambda: toggle_formatting(\"italic\", \"italic\"))\n",
        "italic_btn.pack(side=\"left\", padx=5)\n",
        "\n",
        "underline_btn = tk.Button(toolbar, text=\"Underline\", command=lambda: toggle_formatting(\"underline\", \"underline\"))\n",
        "underline_btn.pack(side=\"left\", padx=5)\n",
        "\n",
        "uppercase_btn = tk.Button(toolbar, text=\"Toggle Case\", command=lambda: toggle_case(\"uppercase\"))\n",
        "uppercase_btn.pack(side=\"left\", padx=5)\n",
        "\n",
        "file_name_label = tk.Label(toolbar, text=\"File Name:\")\n",
        "file_name_label.pack(side=\"right\", padx=5)\n",
        "\n",
        "file_name_entry = tk.Entry(toolbar, width=20)\n",
        "file_name_entry.pack(side=\"right\", padx=5)\n",
        "\n",
        "save_docx_btn = tk.Button(toolbar, text=\"Save as DOCX\", command=save_as_docx)\n",
        "save_docx_btn.pack(side=\"right\", padx=5)\n",
        "\n",
        "theme_button = tk.Button(toolbar, text=\"Change Mode\", command=toggle_theme)\n",
        "theme_button.pack(side=\"right\", padx=5)\n",
        "\n",
        "# Suggestion Label\n",
        "suggestion_label = tk.Label(root, text=f\"Suggested word (Press Tab): {suggested_word}\", font=(\"Arial\", 10), fg=\"blue\")\n",
        "suggestion_label.pack(fill=\"x\")\n",
        "\n",
        "# Text Area\n",
        "text = tk.Text(root, wrap=\"word\", font=(\"Arial\", 12))\n",
        "text.pack(expand=1, fill=\"both\", padx=10, pady=10)\n",
        "\n",
        "# Bind events\n",
        "text.bind(\"<KeyRelease>\", update_last_words)\n",
        "text.bind(\"<Tab>\", insert_suggestion)\n",
        "\n",
        "root.mainloop()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
